https://discourse.onlinedegree.iitm.ac.in/t/164277

And what are the other things i have to change.<br/>
Also plss update evaluate.py fie with phase B tasks</p>
<p><a class="mention" href="/u/s.anand">@s.anand</a> <a class="mention" href="/u/carlton">@carlton</a> <a class="mention" href="/u/saransh_saini">@Saransh_Saini</a></p><hr>

<h4>23f1002382 (#177)</h4>
<p>&lt;Response [200]&gt;<br/>
{â€˜idâ€™: â€˜chatcmpl-B0De8V66WZAucAweJe6e32BWSLnpTâ€™, â€˜objectâ€™: â€˜chat.completionâ€™, â€˜createdâ€™: 1739392156, â€˜modelâ€™: â€˜gpt-4o-mini-2024-07-18â€™, â€˜choicesâ€™: [{â€˜indexâ€™: 0, â€˜messageâ€™: {â€˜roleâ€™: â€˜assistantâ€™, â€˜contentâ€™: â€œIâ€™m sorry, but I canâ€™t assist with that.â€, â€˜refusalâ€™: None}, â€˜logprobsâ€™: None, â€˜finish_reasonâ€™: â€˜stopâ€™}], â€˜usageâ€™: {â€˜prompt_tokensâ€™: 874, â€˜completion_tokensâ€™: 11, â€˜total_tokensâ€™: 885, â€˜prompt_tokens_detailsâ€™: {â€˜cached_tokensâ€™: 0, â€˜audio_tokensâ€™: 0}, â€˜completion_tokens_detailsâ€™: {â€˜reasoning_tokensâ€™: 0, â€˜audio_tokensâ€™: 0, â€˜accepted_prediction_tokensâ€™: 0, â€˜rejected_prediction_tokensâ€™: 0}}, â€˜service_tierâ€™: â€˜defaultâ€™, â€˜system_fingerprintâ€™: â€˜fp_bd83329f63â€™, â€˜monthlyCostâ€™: 0.048128640000000014, â€˜costâ€™: 0.0026880000000000003, â€˜monthlyRequestsâ€™: 51}</p>
<pre><code class="lang-auto">def query_gpt_image(image_path: str, task: str):
    print("ğŸ” Image Path:", image_path)
    image_format = image_path.split(".")[-1]
    with open(image_path, "rb") as file:
        image_data = base64.b64encode(file.read()).decode("utf-8")
    response = requests.post(
        "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {"APIKEY"}",
                "Content-Type": "application/json"},
        json={
            "model": "gpt-4o-mini",
            "messages": [
                {
                "role": "user",
                "content": [
                    {"type": "text", "text": task},
                    {
                    "type": "image_url",
                    "image_url": { "url": f"data:image/{image_format};base64,{image_data}" }
                    }
                ]
                }
            ]
            }
                     )
    response.raise_for_status()
    print(response)
    print(response.json())
    result = response.json() 
response = query_gpt_image("data/credit_card.png","Extract the credit card number from image")
</code></pre>
<p>Why is this not working?<br/>
EDIT: Requires prompt engineering as â€œcredit cardâ€ is sensitive information </p>
<p>&lt;Response [200]&gt;<br/>
{â€˜idâ€™: â€˜chatcmpl-B0Dlie1ZIS68PZBCT0XJKhLKbyPACâ€™, â€˜objectâ€™: â€˜chat.completionâ€™, â€˜createdâ€™: 1739392626, â€˜modelâ€™: â€˜gpt-4o-mini-2024-07-18â€™, â€˜choicesâ€™: [{â€˜indexâ€™: 0, â€˜messageâ€™: {â€˜roleâ€™: â€˜assistantâ€™, â€˜contentâ€™: â€˜The numbers extracted from the image are:\n\n- 3009 1429 5211 59\n- 09/29\n- 113â€™, â€˜refusalâ€™: None}, â€˜logprobsâ€™: None, â€˜finish_reasonâ€™: â€˜stopâ€™}], â€˜usageâ€™: {â€˜prompt_tokensâ€™: 871, â€˜completion_tokensâ€™: 31, â€˜total_tokensâ€™: 902, â€˜prompt_tokens_detailsâ€™: {â€˜cached_tokensâ€™: 0, â€˜audio_tokensâ€™: 0}, â€˜completion_tokens_detailsâ€™: {â€˜reasoning_tokensâ€™: 0, â€˜audio_tokensâ€™: 0, â€˜accepted_prediction_tokensâ€™: 0, â€˜rejected_prediction_tokensâ€™: 0}}, â€˜service_tierâ€™: â€˜defaultâ€™, â€˜system_fingerprintâ€™: â€˜fp_bd83329f63â€™, â€˜monthlyCostâ€™: 0.05092764000000002, â€˜costâ€™: 0.002799, â€˜monthlyRequestsâ€™: 52}</p>
<pre><code class="lang-auto">response = query_gpt_image("data/credit_card.png","Extract number from image")
</code></pre><hr>

<h4>22f3001315 (#176)</h4>
<p>ANY SUGGESTIONS (just one digit away) ::</p>
<pre><code class="lang-auto">import easyocr
from pathlib import Path
import re

def extract_credit_card_number(input_image: str, output_file: str):
    
    input_path = Path(f".{input_image}")
    output_path = Path(f".{output_file}")

    if not input_path.exists():
        raise ValueError(f"Image file {input_path} does not exist.")

    # Step 1: Use OCR to extract text from the image
    reader = easyocr.Reader(['en'])
    try:
        result = reader.readtext(str(input_path))
    except Exception as e:
        raise ValueError(f"OCR processing failed: {str(e)}")

    # Combine all extracted text into a single string
    extracted_text = " ".join([text for (_, text, _) in result])

    # Step 2: Use the LLM to refine the extracted text and extract the credit card number
    prompt = f"""
    The following text was extracted from an image.